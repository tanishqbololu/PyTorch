{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo5WsKtALhkFlj5NuiGs6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishqbololu/PyTorch/blob/main/7_pytorch_training_pipeline_using_dataset_and_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and Dataset"
      ],
      "metadata": {
        "id": "gsw6MpZRFKBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "SL3rEyoJCe27"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "zTb_43LfC_-m",
        "outputId": "68f2e719-b882-4520-dca2-315bd8997be6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8127da32-8c19-4af0-a1a1-5490a4f88c16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8127da32-8c19-4af0-a1a1-5490a4f88c16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8127da32-8c19-4af0-a1a1-5490a4f88c16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8127da32-8c19-4af0-a1a1-5490a4f88c16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmrejroUDXs-",
        "outputId": "1dc15dee-4317-4788-a203-034d332ebd80"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"id\",\"Unnamed: 32\"], inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "pynvJkj-Dcsh",
        "outputId": "96e86979-d439-4f33-882b-43621114443b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fa490dc-0020-473f-92d7-57a0e4ac075e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fa490dc-0020-473f-92d7-57a0e4ac075e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fa490dc-0020-473f-92d7-57a0e4ac075e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fa490dc-0020-473f-92d7-57a0e4ac075e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "cVMc7IWxD2Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:], df.iloc[:,0], test_size=0.2)"
      ],
      "metadata": {
        "id": "rhlTgNo5Dcuu"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "v59LPrbkEOch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)"
      ],
      "metadata": {
        "id": "90EtmxTSDcw2"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZgihJEDDcy1",
        "outputId": "62fcd7ae-d688-4d54-b45a-d71fcdd9a6df"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.50591627, -0.56922028, -1.4817654 , ..., -1.71316083,\n",
              "        -0.72744587,  0.29925315],\n",
              "       [ 1.5645063 ,  1.37721084,  1.53580226, ...,  0.89942079,\n",
              "         0.64633222,  0.06750198],\n",
              "       [-1.23208878, -0.24481509, -1.2624666 , ..., -1.71316083,\n",
              "        -1.58366105, -1.03679233],\n",
              "       ...,\n",
              "       [ 1.75613   ,  0.51683186,  1.62014796, ...,  0.46650455,\n",
              "        -1.05811106, -0.70770567],\n",
              "       [ 0.01763097,  2.01896892,  0.01557151, ..., -0.47339129,\n",
              "        -1.61401196, -0.32010184],\n",
              "       [ 0.2314719 ,  1.39601693,  0.13566372, ..., -1.27587017,\n",
              "        -2.13317229, -1.64803604]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "K3AAjSXeEdU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "DTLm2FOhDc2V"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mTU6eTyDc4S",
        "outputId": "39f9538a-a800-4938-affc-a2cc97aa81f4"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy arrays to PyTorch tensors"
      ],
      "metadata": {
        "id": "tGXJGODxEoEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# float32 because In PyTorch, neural network (nn) parameters and gradients default to float32.\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "y_test_tensor = torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "3kLiqGfuDc5y"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpioS6N0E8MN",
        "outputId": "debc2559-1341-461f-e2fb-aee53066f24b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5059, -0.5692, -1.4818,  ..., -1.7132, -0.7274,  0.2993],\n",
              "        [ 1.5645,  1.3772,  1.5358,  ...,  0.8994,  0.6463,  0.0675],\n",
              "        [-1.2321, -0.2448, -1.2625,  ..., -1.7132, -1.5837, -1.0368],\n",
              "        ...,\n",
              "        [ 1.7561,  0.5168,  1.6201,  ...,  0.4665, -1.0581, -0.7077],\n",
              "        [ 0.0176,  2.0190,  0.0156,  ..., -0.4734, -1.6140, -0.3201],\n",
              "        [ 0.2315,  1.3960,  0.1357,  ..., -1.2759, -2.1332, -1.6480]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3h1hJ27Dc-P",
        "outputId": "f8bdc744-45f9-4ac6-8f24-24baacbb91b2"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lXu3h6VE0TO",
        "outputId": "faf4c654-16a9-4eb1-c74f-eccb502e1554"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([455])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader"
      ],
      "metadata": {
        "id": "6yBuGQ8ZJ8l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, lables):\n",
        "    self.features = features.float()\n",
        "    self.lables = lables.float()\n",
        "    # we need to convert float64 to float32 because pyTorch models give weights in flaot32\n",
        "    # if different dtypes then no matmul and no weight updations\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.features[idx], self.lables[idx]"
      ],
      "metadata": {
        "id": "Dv0VvAmcJ7YC"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "CS34AYSHOMoP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwp8o8zKK6GZ",
        "outputId": "a52e148c-87b1-4f35-d504-ae4095363fee"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2823,  0.3476, -0.2483, -0.3377, -0.6940,  0.0937,  0.2352, -0.3566,\n",
              "         -0.8988, -0.3646, -0.3498, -0.7823, -0.2904, -0.2998,  0.0500,  0.3620,\n",
              "          0.4588,  0.1288, -0.6051, -0.2024, -0.3129, -0.0288, -0.1969, -0.3453,\n",
              "          0.1041,  0.6695,  0.8654,  0.0683, -0.5390, -0.1011]),\n",
              " tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nmXPXkDPmqy",
        "outputId": "0bd35637-4af4-44b1-e9ad-3c88618bca0a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2823,  0.3476, -0.2483, -0.3377, -0.6940,  0.0937,  0.2352, -0.3566,\n",
              "         -0.8988, -0.3646, -0.3498, -0.7823, -0.2904, -0.2998,  0.0500,  0.3620,\n",
              "          0.4588,  0.1288, -0.6051, -0.2024, -0.3129, -0.0288, -0.1969, -0.3453,\n",
              "          0.1041,  0.6695,  0.8654,  0.0683, -0.5390, -0.1011]),\n",
              " tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[10][0].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKuHnrtYPjLH",
        "outputId": "c9bee8d9-c24c-470a-b1b1-c9bc20072476"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "c40XjhpUK_P-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the model"
      ],
      "metadata": {
        "id": "EmZ_bUdTFCYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   We will make a simple NN with one hidden neuron.\n",
        "*   But as our X has 30 features means we will have 30 weights from the input layer to hidden layer\n",
        "\n"
      ],
      "metadata": {
        "id": "0mk8jzqHL3G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "evVbHtm4ijJ5"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "    out = self.linear(features)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "  def loss_function(self, y_pred, y):  # y = true labels -> (train/val/test)\n",
        "    # Clamp predictions to avoid log(0)\n",
        "    epsilon = 1e-7    # 1 * 10^-7 --> 0.0000001\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1-epsilon)\n",
        "\n",
        "    loss = -(y * torch.log(y_pred) + (1-y) * torch.log(1-y_pred)).mean()\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "gdoi2f9UE22M"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Parameters"
      ],
      "metadata": {
        "id": "xAb_EfMkNJid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "GxqoJ0qlLqNj"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline"
      ],
      "metadata": {
        "id": "QOIvJf3aNT53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = MySimpleNN(X_train_tensor.shape[1])\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# define loss function\n",
        "loss_function = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "\n",
        "# Define Loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # Forward Pass\n",
        "    y_pred = model(batch_features)\n",
        "    #print(y_pred)\n",
        "\n",
        "    # Zero Gradients --> Before running new epoch make gradients=0\n",
        "    # model.linear.weight.grad.zero_()\n",
        "    # model.linear.bias.grad.zero_()\n",
        "    optimizer.zero_grad()  #automatically makes all grads zero\n",
        "\n",
        "    # Loss Calculation\n",
        "    #loss = model.loss_function(y_pred, y_train_tensor)\n",
        "    loss = loss_function(y_pred, batch_labels.view(-1,1))  # This is loss fucntion made with nn.BCELoss()\n",
        "    #print(loss)\n",
        "\n",
        "    # Backward Pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Parameters Update -> update weights & bias:\n",
        "    # with torch.no_grad():\n",
        "    #   model.linear.weight -= learning_rate * model.linear.weight.grad   # w_new = w_old - n.dL/dw_old\n",
        "    #   model.linear.bias -= learning_rate * model.linear.bias.grad       # b_new = b_old - n.dL/db_old\n",
        "\n",
        "    optimizer.step()  # -> this will automatically update the weights and bias\n",
        "\n",
        "    # Print loss in each epoch\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\") # .item() converts a scalar tensor into a Python float and removes it from the computation graph, mainly for logging or monitoring.”"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GueK59gnLqPw",
        "outputId": "55a27f3a-03d3-4f91-b122-0d170b4ac4fa"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.7771965861320496\n",
            "Epoch: 0, Loss: 0.45878204703330994\n",
            "Epoch: 0, Loss: 0.46701183915138245\n",
            "Epoch: 0, Loss: 0.4069208800792694\n",
            "Epoch: 0, Loss: 0.283588707447052\n",
            "Epoch: 0, Loss: 0.35568857192993164\n",
            "Epoch: 0, Loss: 0.30755531787872314\n",
            "Epoch: 0, Loss: 0.274344801902771\n",
            "Epoch: 0, Loss: 0.2072087973356247\n",
            "Epoch: 0, Loss: 0.20172002911567688\n",
            "Epoch: 0, Loss: 0.22052724659442902\n",
            "Epoch: 0, Loss: 0.20848579704761505\n",
            "Epoch: 0, Loss: 0.25504904985427856\n",
            "Epoch: 0, Loss: 0.30070191621780396\n",
            "Epoch: 0, Loss: 0.20285211503505707\n",
            "Epoch: 1, Loss: 0.25912997126579285\n",
            "Epoch: 1, Loss: 0.10874348878860474\n",
            "Epoch: 1, Loss: 0.17360180616378784\n",
            "Epoch: 1, Loss: 0.1583614945411682\n",
            "Epoch: 1, Loss: 0.16059142351150513\n",
            "Epoch: 1, Loss: 0.18554344773292542\n",
            "Epoch: 1, Loss: 0.2042340785264969\n",
            "Epoch: 1, Loss: 0.234697163105011\n",
            "Epoch: 1, Loss: 0.1407434046268463\n",
            "Epoch: 1, Loss: 0.1400676816701889\n",
            "Epoch: 1, Loss: 0.2581188678741455\n",
            "Epoch: 1, Loss: 0.1592985987663269\n",
            "Epoch: 1, Loss: 0.13807523250579834\n",
            "Epoch: 1, Loss: 0.16593071818351746\n",
            "Epoch: 1, Loss: 0.07269219309091568\n",
            "Epoch: 2, Loss: 0.14313377439975739\n",
            "Epoch: 2, Loss: 0.17050176858901978\n",
            "Epoch: 2, Loss: 0.1347416490316391\n",
            "Epoch: 2, Loss: 0.11718640476465225\n",
            "Epoch: 2, Loss: 0.08119412511587143\n",
            "Epoch: 2, Loss: 0.13773910701274872\n",
            "Epoch: 2, Loss: 0.2424529641866684\n",
            "Epoch: 2, Loss: 0.16463786363601685\n",
            "Epoch: 2, Loss: 0.15826672315597534\n",
            "Epoch: 2, Loss: 0.09326902031898499\n",
            "Epoch: 2, Loss: 0.07234496623277664\n",
            "Epoch: 2, Loss: 0.16115400195121765\n",
            "Epoch: 2, Loss: 0.12529081106185913\n",
            "Epoch: 2, Loss: 0.14944714307785034\n",
            "Epoch: 2, Loss: 0.43857884407043457\n",
            "Epoch: 3, Loss: 0.15351402759552002\n",
            "Epoch: 3, Loss: 0.18499165773391724\n",
            "Epoch: 3, Loss: 0.12942473590373993\n",
            "Epoch: 3, Loss: 0.12402264028787613\n",
            "Epoch: 3, Loss: 0.053530365228652954\n",
            "Epoch: 3, Loss: 0.07347656041383743\n",
            "Epoch: 3, Loss: 0.14346766471862793\n",
            "Epoch: 3, Loss: 0.18317416310310364\n",
            "Epoch: 3, Loss: 0.08489485830068588\n",
            "Epoch: 3, Loss: 0.1217222809791565\n",
            "Epoch: 3, Loss: 0.1551167368888855\n",
            "Epoch: 3, Loss: 0.15734434127807617\n",
            "Epoch: 3, Loss: 0.09156720340251923\n",
            "Epoch: 3, Loss: 0.11611690372228622\n",
            "Epoch: 3, Loss: 0.2173062115907669\n",
            "Epoch: 4, Loss: 0.11796128004789352\n",
            "Epoch: 4, Loss: 0.07552377879619598\n",
            "Epoch: 4, Loss: 0.09528882801532745\n",
            "Epoch: 4, Loss: 0.07711135596036911\n",
            "Epoch: 4, Loss: 0.15856416523456573\n",
            "Epoch: 4, Loss: 0.09925450384616852\n",
            "Epoch: 4, Loss: 0.08492766320705414\n",
            "Epoch: 4, Loss: 0.14709587395191193\n",
            "Epoch: 4, Loss: 0.14511556923389435\n",
            "Epoch: 4, Loss: 0.10107613354921341\n",
            "Epoch: 4, Loss: 0.05640799179673195\n",
            "Epoch: 4, Loss: 0.12527434527873993\n",
            "Epoch: 4, Loss: 0.25198793411254883\n",
            "Epoch: 4, Loss: 0.08065954595804214\n",
            "Epoch: 4, Loss: 0.19154489040374756\n",
            "Epoch: 5, Loss: 0.13195736706256866\n",
            "Epoch: 5, Loss: 0.09215018898248672\n",
            "Epoch: 5, Loss: 0.06957267969846725\n",
            "Epoch: 5, Loss: 0.05096679925918579\n",
            "Epoch: 5, Loss: 0.12322542071342468\n",
            "Epoch: 5, Loss: 0.14618831872940063\n",
            "Epoch: 5, Loss: 0.10910997539758682\n",
            "Epoch: 5, Loss: 0.20950216054916382\n",
            "Epoch: 5, Loss: 0.09511405229568481\n",
            "Epoch: 5, Loss: 0.12836997210979462\n",
            "Epoch: 5, Loss: 0.10019265115261078\n",
            "Epoch: 5, Loss: 0.08814482390880585\n",
            "Epoch: 5, Loss: 0.1146748885512352\n",
            "Epoch: 5, Loss: 0.07729429751634598\n",
            "Epoch: 5, Loss: 0.024701131507754326\n",
            "Epoch: 6, Loss: 0.14571614563465118\n",
            "Epoch: 6, Loss: 0.08554362505674362\n",
            "Epoch: 6, Loss: 0.10326230525970459\n",
            "Epoch: 6, Loss: 0.07796794921159744\n",
            "Epoch: 6, Loss: 0.09502927958965302\n",
            "Epoch: 6, Loss: 0.1326732635498047\n",
            "Epoch: 6, Loss: 0.08011353015899658\n",
            "Epoch: 6, Loss: 0.14747430384159088\n",
            "Epoch: 6, Loss: 0.1286562830209732\n",
            "Epoch: 6, Loss: 0.04041941836476326\n",
            "Epoch: 6, Loss: 0.05073264613747597\n",
            "Epoch: 6, Loss: 0.19937273859977722\n",
            "Epoch: 6, Loss: 0.07864397019147873\n",
            "Epoch: 6, Loss: 0.08258850872516632\n",
            "Epoch: 6, Loss: 0.056734245270490646\n",
            "Epoch: 7, Loss: 0.0826982781291008\n",
            "Epoch: 7, Loss: 0.05834649130702019\n",
            "Epoch: 7, Loss: 0.14557334780693054\n",
            "Epoch: 7, Loss: 0.08748719841241837\n",
            "Epoch: 7, Loss: 0.07609234005212784\n",
            "Epoch: 7, Loss: 0.1359347403049469\n",
            "Epoch: 7, Loss: 0.06801868975162506\n",
            "Epoch: 7, Loss: 0.09099692851305008\n",
            "Epoch: 7, Loss: 0.18096181750297546\n",
            "Epoch: 7, Loss: 0.06693099439144135\n",
            "Epoch: 7, Loss: 0.08251700550317764\n",
            "Epoch: 7, Loss: 0.06108018383383751\n",
            "Epoch: 7, Loss: 0.14580100774765015\n",
            "Epoch: 7, Loss: 0.0578574538230896\n",
            "Epoch: 7, Loss: 0.2557533383369446\n",
            "Epoch: 8, Loss: 0.10502272099256516\n",
            "Epoch: 8, Loss: 0.06233338639140129\n",
            "Epoch: 8, Loss: 0.08495493978261948\n",
            "Epoch: 8, Loss: 0.08581975102424622\n",
            "Epoch: 8, Loss: 0.18658097088336945\n",
            "Epoch: 8, Loss: 0.09047871828079224\n",
            "Epoch: 8, Loss: 0.12657088041305542\n",
            "Epoch: 8, Loss: 0.10059022903442383\n",
            "Epoch: 8, Loss: 0.08547354489564896\n",
            "Epoch: 8, Loss: 0.05629244074225426\n",
            "Epoch: 8, Loss: 0.09003549814224243\n",
            "Epoch: 8, Loss: 0.10229223221540451\n",
            "Epoch: 8, Loss: 0.060804855078458786\n",
            "Epoch: 8, Loss: 0.09130711853504181\n",
            "Epoch: 8, Loss: 0.07012225687503815\n",
            "Epoch: 9, Loss: 0.08302832394838333\n",
            "Epoch: 9, Loss: 0.18666313588619232\n",
            "Epoch: 9, Loss: 0.06891317665576935\n",
            "Epoch: 9, Loss: 0.05454802140593529\n",
            "Epoch: 9, Loss: 0.046121299266815186\n",
            "Epoch: 9, Loss: 0.03818453848361969\n",
            "Epoch: 9, Loss: 0.12714235484600067\n",
            "Epoch: 9, Loss: 0.08790956437587738\n",
            "Epoch: 9, Loss: 0.07291674613952637\n",
            "Epoch: 9, Loss: 0.10783702880144119\n",
            "Epoch: 9, Loss: 0.060121674090623856\n",
            "Epoch: 9, Loss: 0.10212861001491547\n",
            "Epoch: 9, Loss: 0.101280577480793\n",
            "Epoch: 9, Loss: 0.1459948867559433\n",
            "Epoch: 9, Loss: 0.07428493350744247\n",
            "Epoch: 10, Loss: 0.06186847388744354\n",
            "Epoch: 10, Loss: 0.08715894818305969\n",
            "Epoch: 10, Loss: 0.08515918254852295\n",
            "Epoch: 10, Loss: 0.1080804169178009\n",
            "Epoch: 10, Loss: 0.1735285371541977\n",
            "Epoch: 10, Loss: 0.1651843637228012\n",
            "Epoch: 10, Loss: 0.05469734966754913\n",
            "Epoch: 10, Loss: 0.05537184327840805\n",
            "Epoch: 10, Loss: 0.03612641245126724\n",
            "Epoch: 10, Loss: 0.03731808438897133\n",
            "Epoch: 10, Loss: 0.05330917611718178\n",
            "Epoch: 10, Loss: 0.06055527552962303\n",
            "Epoch: 10, Loss: 0.1360747516155243\n",
            "Epoch: 10, Loss: 0.0892907977104187\n",
            "Epoch: 10, Loss: 0.25393739342689514\n",
            "Epoch: 11, Loss: 0.1583600491285324\n",
            "Epoch: 11, Loss: 0.04829194024205208\n",
            "Epoch: 11, Loss: 0.21889442205429077\n",
            "Epoch: 11, Loss: 0.07479860633611679\n",
            "Epoch: 11, Loss: 0.0674203559756279\n",
            "Epoch: 11, Loss: 0.0707205981016159\n",
            "Epoch: 11, Loss: 0.05680186301469803\n",
            "Epoch: 11, Loss: 0.07013943791389465\n",
            "Epoch: 11, Loss: 0.10713056474924088\n",
            "Epoch: 11, Loss: 0.0539262518286705\n",
            "Epoch: 11, Loss: 0.057287558913230896\n",
            "Epoch: 11, Loss: 0.12101232260465622\n",
            "Epoch: 11, Loss: 0.06320678442716599\n",
            "Epoch: 11, Loss: 0.051683057099580765\n",
            "Epoch: 11, Loss: 0.050233688205480576\n",
            "Epoch: 12, Loss: 0.13882781565189362\n",
            "Epoch: 12, Loss: 0.08490090817213058\n",
            "Epoch: 12, Loss: 0.028033077716827393\n",
            "Epoch: 12, Loss: 0.03477812185883522\n",
            "Epoch: 12, Loss: 0.12448186427354813\n",
            "Epoch: 12, Loss: 0.1379481852054596\n",
            "Epoch: 12, Loss: 0.08055237680673599\n",
            "Epoch: 12, Loss: 0.06816184520721436\n",
            "Epoch: 12, Loss: 0.05370917543768883\n",
            "Epoch: 12, Loss: 0.04186588153243065\n",
            "Epoch: 12, Loss: 0.07983508706092834\n",
            "Epoch: 12, Loss: 0.057714417576789856\n",
            "Epoch: 12, Loss: 0.0766758993268013\n",
            "Epoch: 12, Loss: 0.06735667586326599\n",
            "Epoch: 12, Loss: 0.5817790031433105\n",
            "Epoch: 13, Loss: 0.10693615674972534\n",
            "Epoch: 13, Loss: 0.054759588092565536\n",
            "Epoch: 13, Loss: 0.08560390025377274\n",
            "Epoch: 13, Loss: 0.053795069456100464\n",
            "Epoch: 13, Loss: 0.04517333582043648\n",
            "Epoch: 13, Loss: 0.07050502300262451\n",
            "Epoch: 13, Loss: 0.09635899215936661\n",
            "Epoch: 13, Loss: 0.030031248927116394\n",
            "Epoch: 13, Loss: 0.09953543543815613\n",
            "Epoch: 13, Loss: 0.14827069640159607\n",
            "Epoch: 13, Loss: 0.19569432735443115\n",
            "Epoch: 13, Loss: 0.03304685652256012\n",
            "Epoch: 13, Loss: 0.08008429408073425\n",
            "Epoch: 13, Loss: 0.03680742159485817\n",
            "Epoch: 13, Loss: 0.2244173288345337\n",
            "Epoch: 14, Loss: 0.06834946572780609\n",
            "Epoch: 14, Loss: 0.07765877991914749\n",
            "Epoch: 14, Loss: 0.05883223935961723\n",
            "Epoch: 14, Loss: 0.0396764874458313\n",
            "Epoch: 14, Loss: 0.2455649971961975\n",
            "Epoch: 14, Loss: 0.0647055134177208\n",
            "Epoch: 14, Loss: 0.14903609454631805\n",
            "Epoch: 14, Loss: 0.04222676157951355\n",
            "Epoch: 14, Loss: 0.09442269057035446\n",
            "Epoch: 14, Loss: 0.028491714969277382\n",
            "Epoch: 14, Loss: 0.07682092487812042\n",
            "Epoch: 14, Loss: 0.03125552833080292\n",
            "Epoch: 14, Loss: 0.09043551981449127\n",
            "Epoch: 14, Loss: 0.07349531352519989\n",
            "Epoch: 14, Loss: 0.11544782668352127\n",
            "Epoch: 15, Loss: 0.04360640048980713\n",
            "Epoch: 15, Loss: 0.0466742105782032\n",
            "Epoch: 15, Loss: 0.05885579064488411\n",
            "Epoch: 15, Loss: 0.17434905469417572\n",
            "Epoch: 15, Loss: 0.031706370413303375\n",
            "Epoch: 15, Loss: 0.05445367842912674\n",
            "Epoch: 15, Loss: 0.08111937344074249\n",
            "Epoch: 15, Loss: 0.05649945139884949\n",
            "Epoch: 15, Loss: 0.07208559662103653\n",
            "Epoch: 15, Loss: 0.09438759088516235\n",
            "Epoch: 15, Loss: 0.102501779794693\n",
            "Epoch: 15, Loss: 0.18902234733104706\n",
            "Epoch: 15, Loss: 0.03348438814282417\n",
            "Epoch: 15, Loss: 0.07122476398944855\n",
            "Epoch: 15, Loss: 0.15553715825080872\n",
            "Epoch: 16, Loss: 0.05114687606692314\n",
            "Epoch: 16, Loss: 0.11532057821750641\n",
            "Epoch: 16, Loss: 0.05413225293159485\n",
            "Epoch: 16, Loss: 0.05143190175294876\n",
            "Epoch: 16, Loss: 0.04193117469549179\n",
            "Epoch: 16, Loss: 0.0828692838549614\n",
            "Epoch: 16, Loss: 0.15796655416488647\n",
            "Epoch: 16, Loss: 0.10122527182102203\n",
            "Epoch: 16, Loss: 0.09578597545623779\n",
            "Epoch: 16, Loss: 0.08809313178062439\n",
            "Epoch: 16, Loss: 0.03958422690629959\n",
            "Epoch: 16, Loss: 0.047344308346509933\n",
            "Epoch: 16, Loss: 0.05550003424286842\n",
            "Epoch: 16, Loss: 0.11631426215171814\n",
            "Epoch: 16, Loss: 0.10388921946287155\n",
            "Epoch: 17, Loss: 0.0662449300289154\n",
            "Epoch: 17, Loss: 0.0451817587018013\n",
            "Epoch: 17, Loss: 0.1205797791481018\n",
            "Epoch: 17, Loss: 0.07312856614589691\n",
            "Epoch: 17, Loss: 0.03983646258711815\n",
            "Epoch: 17, Loss: 0.0651933029294014\n",
            "Epoch: 17, Loss: 0.0674024224281311\n",
            "Epoch: 17, Loss: 0.18463434278964996\n",
            "Epoch: 17, Loss: 0.16737906634807587\n",
            "Epoch: 17, Loss: 0.07434166222810745\n",
            "Epoch: 17, Loss: 0.027770858258008957\n",
            "Epoch: 17, Loss: 0.06704443693161011\n",
            "Epoch: 17, Loss: 0.04536011070013046\n",
            "Epoch: 17, Loss: 0.055484045296907425\n",
            "Epoch: 17, Loss: 0.022511916235089302\n",
            "Epoch: 18, Loss: 0.08968814462423325\n",
            "Epoch: 18, Loss: 0.05195010453462601\n",
            "Epoch: 18, Loss: 0.14827972650527954\n",
            "Epoch: 18, Loss: 0.06914321333169937\n",
            "Epoch: 18, Loss: 0.10060463845729828\n",
            "Epoch: 18, Loss: 0.041110698133707047\n",
            "Epoch: 18, Loss: 0.022702230140566826\n",
            "Epoch: 18, Loss: 0.030489183962345123\n",
            "Epoch: 18, Loss: 0.05046922713518143\n",
            "Epoch: 18, Loss: 0.05543145164847374\n",
            "Epoch: 18, Loss: 0.1286173164844513\n",
            "Epoch: 18, Loss: 0.19379588961601257\n",
            "Epoch: 18, Loss: 0.07693642377853394\n",
            "Epoch: 18, Loss: 0.024093305692076683\n",
            "Epoch: 18, Loss: 0.022915169596672058\n",
            "Epoch: 19, Loss: 0.16954007744789124\n",
            "Epoch: 19, Loss: 0.047403570264577866\n",
            "Epoch: 19, Loss: 0.13189725577831268\n",
            "Epoch: 19, Loss: 0.07931483536958694\n",
            "Epoch: 19, Loss: 0.09343171864748001\n",
            "Epoch: 19, Loss: 0.02930363453924656\n",
            "Epoch: 19, Loss: 0.07417241483926773\n",
            "Epoch: 19, Loss: 0.06471925228834152\n",
            "Epoch: 19, Loss: 0.039095085114240646\n",
            "Epoch: 19, Loss: 0.06022892892360687\n",
            "Epoch: 19, Loss: 0.06123225390911102\n",
            "Epoch: 19, Loss: 0.0950104296207428\n",
            "Epoch: 19, Loss: 0.03099871426820755\n",
            "Epoch: 19, Loss: 0.08923850953578949\n",
            "Epoch: 19, Loss: 0.040477167814970016\n",
            "Epoch: 20, Loss: 0.0682232528924942\n",
            "Epoch: 20, Loss: 0.019805170595645905\n",
            "Epoch: 20, Loss: 0.08809436857700348\n",
            "Epoch: 20, Loss: 0.026319660246372223\n",
            "Epoch: 20, Loss: 0.05122840777039528\n",
            "Epoch: 20, Loss: 0.09787128120660782\n",
            "Epoch: 20, Loss: 0.06599754840135574\n",
            "Epoch: 20, Loss: 0.053412191569805145\n",
            "Epoch: 20, Loss: 0.06225798651576042\n",
            "Epoch: 20, Loss: 0.13594192266464233\n",
            "Epoch: 20, Loss: 0.047551725059747696\n",
            "Epoch: 20, Loss: 0.04740897938609123\n",
            "Epoch: 20, Loss: 0.20672251284122467\n",
            "Epoch: 20, Loss: 0.07962562143802643\n",
            "Epoch: 20, Loss: 0.0482344813644886\n",
            "Epoch: 21, Loss: 0.0643121674656868\n",
            "Epoch: 21, Loss: 0.04135948419570923\n",
            "Epoch: 21, Loss: 0.2401059865951538\n",
            "Epoch: 21, Loss: 0.026484183967113495\n",
            "Epoch: 21, Loss: 0.043867457658052444\n",
            "Epoch: 21, Loss: 0.05791107565164566\n",
            "Epoch: 21, Loss: 0.10372783988714218\n",
            "Epoch: 21, Loss: 0.049893446266651154\n",
            "Epoch: 21, Loss: 0.045610420405864716\n",
            "Epoch: 21, Loss: 0.057427551597356796\n",
            "Epoch: 21, Loss: 0.06566961109638214\n",
            "Epoch: 21, Loss: 0.12664178013801575\n",
            "Epoch: 21, Loss: 0.03706825524568558\n",
            "Epoch: 21, Loss: 0.08834998309612274\n",
            "Epoch: 21, Loss: 0.00766474986448884\n",
            "Epoch: 22, Loss: 0.09912820905447006\n",
            "Epoch: 22, Loss: 0.04357711598277092\n",
            "Epoch: 22, Loss: 0.031652677804231644\n",
            "Epoch: 22, Loss: 0.10130476951599121\n",
            "Epoch: 22, Loss: 0.11016997694969177\n",
            "Epoch: 22, Loss: 0.06297755241394043\n",
            "Epoch: 22, Loss: 0.05025479197502136\n",
            "Epoch: 22, Loss: 0.0869951844215393\n",
            "Epoch: 22, Loss: 0.08545331656932831\n",
            "Epoch: 22, Loss: 0.06231711804866791\n",
            "Epoch: 22, Loss: 0.06413063406944275\n",
            "Epoch: 22, Loss: 0.15740154683589935\n",
            "Epoch: 22, Loss: 0.03883647173643112\n",
            "Epoch: 22, Loss: 0.04100276902318001\n",
            "Epoch: 22, Loss: 0.008147785440087318\n",
            "Epoch: 23, Loss: 0.03502410277724266\n",
            "Epoch: 23, Loss: 0.06265662610530853\n",
            "Epoch: 23, Loss: 0.0724329948425293\n",
            "Epoch: 23, Loss: 0.231636181473732\n",
            "Epoch: 23, Loss: 0.09377813339233398\n",
            "Epoch: 23, Loss: 0.06976185739040375\n",
            "Epoch: 23, Loss: 0.0384836345911026\n",
            "Epoch: 23, Loss: 0.024567440152168274\n",
            "Epoch: 23, Loss: 0.07118605077266693\n",
            "Epoch: 23, Loss: 0.03645702078938484\n",
            "Epoch: 23, Loss: 0.10264606773853302\n",
            "Epoch: 23, Loss: 0.10339677333831787\n",
            "Epoch: 23, Loss: 0.034488655626773834\n",
            "Epoch: 23, Loss: 0.04763723909854889\n",
            "Epoch: 23, Loss: 0.0125806899741292\n",
            "Epoch: 24, Loss: 0.02884630672633648\n",
            "Epoch: 24, Loss: 0.05230243131518364\n",
            "Epoch: 24, Loss: 0.11711114645004272\n",
            "Epoch: 24, Loss: 0.1436443030834198\n",
            "Epoch: 24, Loss: 0.06270311772823334\n",
            "Epoch: 24, Loss: 0.041946783661842346\n",
            "Epoch: 24, Loss: 0.042705729603767395\n",
            "Epoch: 24, Loss: 0.2301015704870224\n",
            "Epoch: 24, Loss: 0.023161254823207855\n",
            "Epoch: 24, Loss: 0.049872420728206635\n",
            "Epoch: 24, Loss: 0.023110482841730118\n",
            "Epoch: 24, Loss: 0.03570932894945145\n",
            "Epoch: 24, Loss: 0.10347577184438705\n",
            "Epoch: 24, Loss: 0.024208631366491318\n",
            "Epoch: 24, Loss: 0.18105654418468475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9yuW-HDQLg4",
        "outputId": "2815e7a7-e18a-43b8-cd21-623552e69b68"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.7346,  0.6212,  0.4476,  0.4321,  0.2473,  0.0876,  0.3348,  0.5438,\n",
              "          0.0963, -0.2179,  0.6288, -0.0517,  0.5175,  0.5698,  0.1458, -0.3415,\n",
              "         -0.1512,  0.1746, -0.1003, -0.3302,  0.5218,  0.7561,  0.8221,  0.4629,\n",
              "          0.4734,  0.3035,  0.5427,  0.6344,  0.2916,  0.2325]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI090SSGSQpf",
        "outputId": "6ed2935f-eba9-44fb-f9b4-1291627481c5"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.2610], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "EaHkZqdtSYMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation using test_loader\n",
        "model.eval()         # set model to evaluation mode\n",
        "accuracy_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    y_pred = model(batch_features)\n",
        "    y_pred = (y_pred > 0.8).float() # Convert probabilities to binary predictions\n",
        "\n",
        "    # Calculate accuracy for current batch\n",
        "    batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean()\n",
        "    accuracy_list.append(batch_accuracy.item())\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "print(f\"Accuracy: {overall_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNwrq2OtQmZB",
        "outputId": "7e172d25-5c4d-492e-cfff-def59e4ad952"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9704861044883728\n"
          ]
        }
      ]
    }
  ]
}